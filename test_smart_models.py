import requests
import time

def test_all_models():
    """æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
    print("ğŸ§ª æ™ºèƒ½æ¨¡å‹æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    api_key = "sk-dhseqxecuwwotodiskfdgwdjahnbexcgdotkfsovbgajxnis"
    api_url = "https://api.siliconflow.cn/v1/chat/completions"
    
    # æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰æ‚¨çš„è¦æ±‚ï¼‰
    models = [
        # ä¸»æ¨æ¨¡å‹
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-R1",
        
        # Qwenç³»åˆ—
        "Qwen/Qwen2.5-7B-Instruct",
        "Qwen/Qwen2.5-14B-Instruct", 
        "Qwen/Qwen2.5-32B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct",
        
        # è§†è§‰æ¨¡å‹
        "Qwen/Qwen2.5-VL-32B-Instruct",
        "Qwen/Qwen2.5-VL-72B-Instruct",
        
        # ç‰¹æ®Šæ¨¡å‹
        "Qwen/QVQ-72B-Preview",
        "Qwen/QwQ-32B"
    ]
    
    # æµ‹è¯•æ¶ˆæ¯ï¼ˆä¸åŒå¤æ‚åº¦ï¼‰
    test_messages = [
        {
            "content": "ä½ å¥½",
            "complexity": "ç®€å•",
            "expected_model": "7Bæˆ–14B"
        },
        {
            "content": "è¯·è¯¦ç»†è§£é‡Šé‡å­åŠ›å­¦çš„åŸºæœ¬åŸç†å’Œåº”ç”¨",
            "complexity": "å¤æ‚",
            "expected_model": "72Bæˆ–DeepSeek"
        },
        {
            "content": "å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªæŠ•èµ„æ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹",
            "complexity": "ä¸­ç­‰",
            "expected_model": "32Bæˆ–DeepSeek-V3"
        }
    ]
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    available_models = []
    
    print("ğŸ” æ­£åœ¨æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§...")
    
    for i, model in enumerate(models, 1):
        print(f"\nğŸ“¡ æµ‹è¯•æ¨¡å‹ {i}/{len(models)}: {model}")
        
        data = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": "ä½ å¥½ï¼Œè¯·å›å¤'æµ‹è¯•æˆåŠŸ'"
                }
            ],
            "max_tokens": 50,
            "temperature": 0.7
        }
        
        try:
            start_time = time.time()
            response = requests.post(api_url, headers=headers, json=data, timeout=30)
            end_time = time.time()
            
            response_time = end_time - start_time
            
            if response.status_code == 200:
                result = response.json()
                reply = result['choices'][0]['message']['content']
                usage = result.get('usage', {})
                
                model_info = {
                    "name": model,
                    "status": "âœ… å¯ç”¨",
                    "response_time": response_time,
                    "reply": reply,
                    "tokens": usage.get('total_tokens', 0)
                }
                
                available_models.append(model_info)
                
                print(f"   âœ… å¯ç”¨ - {response_time:.2f}ç§’")
                print(f"   ğŸ¤– å›å¤: {reply}")
                print(f"   ğŸ“Š Token: {usage.get('total_tokens', 0)}")
                
            else:
                print(f"   âŒ ä¸å¯ç”¨ - HTTP {response.status_code}")
                error_data = response.json() if response.content else {}
                if 'message' in error_data:
                    print(f"   ğŸ“ é”™è¯¯: {error_data['message']}")
                    
        except requests.exceptions.Timeout:
            print("   â° è¯·æ±‚è¶…æ—¶")
        except Exception as e:
            print(f"   âŒ å¼‚å¸¸: {e}")
        
        # é¿å…é¢‘ç‡é™åˆ¶
        time.sleep(1)
    
    # æ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("=" * 60)
    
    print(f"âœ… å¯ç”¨æ¨¡å‹: {len(available_models)}/{len(models)}")
    
    if available_models:
        print("\nğŸ† æ¨èé…ç½®:")
        
        # æŒ‰å“åº”æ—¶é—´åˆ†ç±»
        fast_models = [m for m in available_models if m['response_time'] < 5]
        medium_models = [m for m in available_models if 5 <= m['response_time'] < 15]
        slow_models = [m for m in available_models if m['response_time'] >= 15]
        
        if fast_models:
            print("\nğŸƒ å¿«é€Ÿæ¨¡å‹ï¼ˆç®€å•å¯¹è¯ï¼‰:")
            for model in fast_models[:3]:
                print(f"   - {model['name']} ({model['response_time']:.1f}s)")
        
        if medium_models:
            print("\nğŸš¶ ä¸­é€Ÿæ¨¡å‹ï¼ˆä¸€èˆ¬é—®é¢˜ï¼‰:")
            for model in medium_models[:3]:
                print(f"   - {model['name']} ({model['response_time']:.1f}s)")
        
        if slow_models:
            print("\nğŸ§  æ·±åº¦æ¨¡å‹ï¼ˆå¤æ‚æ¨ç†ï¼‰:")
            for model in slow_models[:3]:
                print(f"   - {model['name']} ({model['response_time']:.1f}s)")
        
        # ç‰¹æ®Šæ¨è
        print("\nâ­ ç‰¹åˆ«æ¨è:")
        deepseek_models = [m for m in available_models if 'DeepSeek' in m['name']]
        if deepseek_models:
            print("   ğŸ¤– DeepSeekç³»åˆ—ï¼ˆæ¨ç†èƒ½åŠ›å¼ºï¼‰:")
            for model in deepseek_models:
                print(f"     - {model['name']}")
        
        qwen_large = [m for m in available_models if 'Qwen' in m['name'] and ('72B' in m['name'] or '32B' in m['name'])]
        if qwen_large:
            print("   ğŸ§ª Qwenå¤§æ¨¡å‹ï¼ˆç»¼åˆèƒ½åŠ›å¼ºï¼‰:")
            for model in qwen_large:
                print(f"     - {model['name']}")
    
    return available_models

def test_intelligent_selection():
    """æµ‹è¯•æ™ºèƒ½æ¨¡å‹é€‰æ‹©é€»è¾‘"""
    print("\nğŸ§  æ™ºèƒ½é€‰æ‹©æµ‹è¯•")
    print("=" * 40)
    
    # æ¨¡æ‹Ÿä¸åŒå¤æ‚åº¦çš„æ¶ˆæ¯
    test_cases = [
        {
            "message": "ä½ å¥½",
            "expected_complexity": "simple",
            "description": "ç®€å•é—®å€™"
        },
        {
            "message": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "expected_complexity": "simple", 
            "description": "æ—¥å¸¸è¯¢é—®"
        },
        {
            "message": "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªå•†ä¸šè®¡åˆ’ä¹¦çš„å¯è¡Œæ€§",
            "expected_complexity": "medium",
            "description": "åˆ†æç±»é—®é¢˜"
        },
        {
            "message": "èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹æ·±åº¦å­¦ä¹ ä¸­çš„åå‘ä¼ æ’­ç®—æ³•åŸç†å—ï¼ŸåŒ…æ‹¬æ•°å­¦æ¨å¯¼è¿‡ç¨‹",
            "expected_complexity": "complex",
            "description": "å¤æ‚æŠ€æœ¯é—®é¢˜"
        },
        {
            "message": "ä¸ºä»€ä¹ˆé‡å­è®¡ç®—æœºèƒ½å¤Ÿå®ç°æŒ‡æ•°çº§åŠ é€Ÿï¼Ÿè¯·ä»ç‰©ç†åŸç†è§’åº¦æ·±å…¥åˆ†æ",
            "expected_complexity": "complex", 
            "description": "æ·±åº¦ç§‘å­¦é—®é¢˜"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        message = case["message"]
        expected = case["expected_complexity"]
        description = case["description"]
        
        print(f"\næµ‹è¯• {i}: {description}")
        print(f"æ¶ˆæ¯: {message}")
        
        # ç®€åŒ–çš„å¤æ‚åº¦åˆ†æé€»è¾‘
        complexity = analyze_message_complexity_simple(message)
        
        print(f"é¢„æœŸå¤æ‚åº¦: {expected}")
        print(f"åˆ†æç»“æœ: {complexity}")
        print(f"åŒ¹é…åº¦: {'âœ… æ­£ç¡®' if complexity == expected else 'âŒ éœ€è¦è°ƒæ•´'}")

def analyze_message_complexity_simple(message):
    """ç®€åŒ–ç‰ˆæ¶ˆæ¯å¤æ‚åº¦åˆ†æ"""
    if not message or len(message) < 5:
        return "simple"
    
    complex_keywords = [
        "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•", "åˆ†æ", "è§£é‡Š", "åŸç†", "æœºåˆ¶",
        "æ¨ç†", "é€»è¾‘", "è¯æ˜", "è®¡ç®—", "è¯¦ç»†", "æ·±å…¥", "ä¸“ä¸š",
        "ç®—æ³•", "æ•°å­¦", "ç‰©ç†", "åŒ–å­¦", "é‡å­", "æ·±åº¦å­¦ä¹ "
    ]
    
    medium_keywords = [
        "ä»€ä¹ˆ", "å“ªä¸ª", "å»ºè®®", "æ¨è", "æ¯”è¾ƒ", "åŒºåˆ«", "é€‰æ‹©",
        "æ–¹æ³•", "æ­¥éª¤", "ä»‹ç»", "è¯´æ˜", "æ€»ç»“", "åˆ†æ"
    ]
    
    message_lower = message.lower()
    
    complex_count = sum(1 for word in complex_keywords if word in message_lower)
    medium_count = sum(1 for word in medium_keywords if word in message_lower)
    
    if complex_count > 0 or len(message) > 100:
        return "complex"
    elif medium_count > 0 or len(message) > 50:
        return "medium"
    else:
        return "simple"

def main():
    print("ğŸ¤– æ™ºèƒ½æ¨¡å‹æµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    choice = input("é€‰æ‹©æµ‹è¯•:\n1. æµ‹è¯•æ‰€æœ‰æ¨¡å‹å¯ç”¨æ€§\n2. æµ‹è¯•æ™ºèƒ½é€‰æ‹©é€»è¾‘\n3. å…¨é¢æµ‹è¯•\nè¯·é€‰æ‹© (1-3): ")
    
    if choice == "1":
        available_models = test_all_models()
        
        if available_models:
            print(f"\nâœ… æµ‹è¯•å®Œæˆï¼å‘ç° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹")
            print("ğŸ’¡ æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨æ™ºèƒ½å¾®ä¿¡æœºå™¨äººäº†")
        else:
            print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’ŒAPIé…ç½®")
            
    elif choice == "2":
        test_intelligent_selection()
        
    elif choice == "3":
        print("ğŸš€ å¼€å§‹å…¨é¢æµ‹è¯•...")
        available_models = test_all_models()
        test_intelligent_selection()
        
        print("\nğŸ‰ å…¨é¢æµ‹è¯•å®Œæˆ!")
        if available_models:
            print(f"âœ… ç³»ç»Ÿå°±ç»ªï¼Œå‘ç° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹")
        
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main() 